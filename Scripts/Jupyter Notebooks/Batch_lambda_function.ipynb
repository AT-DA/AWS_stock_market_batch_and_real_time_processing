{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**\n",
    "\n",
    "This jupter notebok file contains the script of the function process_batch_files_lambda() that's used for batch processing. When a new file is generated using Batch_Prices.ipynb, the function handles the data and loads into the s3 while making sure that there are no duplicates.\n",
    "The actual execution is actually done in AWS lambda service, but the code used here is written just as simulation to make sure that there are no errors or any bugs. Once the code runs without any errors/bugs, it will be executed in AWS lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from random import randrange\n",
    "from pandasql import sqldf\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new_file = pd.read_csv('s3://stock-market-raw-data-us-east-1/stg_price_by_date/test_data.csv')\n",
    "df_new_file = pd.read_csv('s3://stock-market-raw-data-us-east-1/stg_price_by_date/20250131175440.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_athena = wr.athena.read_sql_query('SELECT * FROM price_by_date', database = 'stock_market')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string to date python date object\n",
    "\n",
    "df_new_records['close_date'] = df_new_records['close_date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').date()) \n",
    "\n",
    "#OR\n",
    "\n",
    "#df_new_records['close_date'] = pd.to_datetime(df_new_records['close_date']).dt.date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the partition column\n",
    "df_new_records['p_year'] = pd.to_datetime(df_new_records['close_date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a PyArrow Table\n",
    "table = pa.Table.from_pandas(df_new_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Parquet with partitioning by year\n",
    "s3_path = 's3://stock-market-raw-data-us-east-1/price_by_date/'\n",
    "pq.write_to_dataset(table, root_path = s3_path, partition_cols=['p_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-542-14245a7c672c>:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_athena = pd.read_sql('select * from AwsDataCatalog.stock_market.price_by_date', conn)\n"
     ]
    }
   ],
   "source": [
    "path = 's3://stock-market-raw-data-us-east-1/stg_price_by_date/20250131163557.csv'\n",
    "process_batch_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3://stock-market-raw-data-us-east-1/stg_price_by_date/20250131172624.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_file = pd.read_csv('s3://stock-market-raw-data-us-east-1/stg_price_by_date/20250131175440.csv')\n",
    "df_new_file['date'] = df_new_file['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').date()) \n",
    "df_athena = wr.athena.read_sql_query('SELECT * FROM price_by_date', database = 'stock_market')\n",
    "merged_df = pd.merge(df_new_file, df_athena, how='left', left_on=['company', 'date'], right_on=['company', 'close_date'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>close_price_x</th>\n",
       "      <th>close_date</th>\n",
       "      <th>close_price_y</th>\n",
       "      <th>p_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>151</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>151</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>207</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>207</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>417</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>417</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>213</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>213</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>195</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>195</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>696</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>696</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>372</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>372</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>98</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>98</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>242</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>242</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>350</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>350</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>182</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>182</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MA</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>455</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>455</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>111</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>111</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>990</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>990</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PG</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>151</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>151</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SAP</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>284</td>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>284</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company        date  close_price_x  close_date  close_price_y  p_year\n",
       "0     NVDA  2024-12-08            151  2024-12-08            151    2024\n",
       "1     AAPL  2024-12-08            207  2024-12-08            207    2024\n",
       "2     MSFT  2024-12-08            417  2024-12-08            417    2024\n",
       "3     AMZN  2024-12-08            213  2024-12-08            213    2024\n",
       "4    GOOGL  2024-12-08            195  2024-12-08            195    2024\n",
       "5     META  2024-12-08            696  2024-12-08            696    2024\n",
       "6     TSLA  2024-12-08            372  2024-12-08            372    2024\n",
       "7      WMT  2024-12-08             98  2024-12-08             98    2024\n",
       "8      JPM  2024-12-08            242  2024-12-08            242    2024\n",
       "9        V  2024-12-08            350  2024-12-08            350    2024\n",
       "10    ORCL  2024-12-08            182  2024-12-08            182    2024\n",
       "11      MA  2024-12-08            455  2024-12-08            455    2024\n",
       "12     XOM  2024-12-08            111  2024-12-08            111    2024\n",
       "13    NFLX  2024-12-08            990  2024-12-08            990    2024\n",
       "14      PG  2024-12-08            151  2024-12-08            151    2024\n",
       "15     SAP  2024-12-08            284  2024-12-08            284    2024"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_files_lambda(event, context):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from datetime import datetime, timedelta\n",
    "    from random import randrange\n",
    "    import awswrangler as wr\n",
    "\n",
    "    \n",
    "    source_bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "    path = source_bucket + key\n",
    "    \n",
    "    df_new_file = wr.s3.read_csv(path)\n",
    "    df_new_file['date'] = df_new_file['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').date()) \n",
    "\n",
    "    \n",
    "    df_athena = wr.athena.read_sql_query('SELECT * FROM price_by_date', database = 'stock_market')\n",
    "    \n",
    "    # Perform the left join and get records in df_new_file and not in df_athena\n",
    "    merged_df = pd.merge(df_new_file, df_athena, how='left', left_on=['company', 'date'], right_on=['company', 'close_date'] )\n",
    "    df_new_records = merged_df[merged_df['close_price_y'].isnull()][['company', 'date', 'close_price_x']]\n",
    "    df_new_records.columns = ['company', 'close_date', 'close_price']\n",
    "        \n",
    "    df_new_records['p_year'] = pd.to_datetime(df_new_records['close_date']).dt.year\n",
    "    \n",
    "    dest_path = 's3://stock-market-raw-data-us-east-1/price_by_date/'\n",
    "\n",
    "    wr.s3.to_parquet(df=df_new_records, path=dest_path, index=False, dataset=True, partition_cols=['p_year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = \\\n",
    "{  \n",
    "   \"Records\":[  \n",
    "      {  \n",
    "         \"eventVersion\":\"2.2\",\n",
    "         \"eventSource\":\"aws:s3\",\n",
    "         \"awsRegion\":\"us-west-2\",\n",
    "         \"eventTime\":\"The time, in ISO-8601 format, for example, 1970-01-01T00:00:00.000Z, when Amazon S3 finished processing the request\",\n",
    "         \"eventName\":\"event-type\",\n",
    "         \"userIdentity\":{  \n",
    "            \"principalId\":\"Amazon-customer-ID-of-the-user-who-caused-the-event\"\n",
    "         },\n",
    "         \"requestParameters\":{  \n",
    "            \"sourceIPAddress\":\"ip-address-where-request-came-from\"\n",
    "         },\n",
    "         \"responseElements\":{  \n",
    "            \"x-amz-request-id\":\"Amazon S3 generated request ID\",\n",
    "            \"x-amz-id-2\":\"Amazon S3 host that processed the request\"\n",
    "         },\n",
    "         \"s3\":{  \n",
    "            \"s3SchemaVersion\":\"1.0\",\n",
    "            \"configurationId\":\"ID found in the bucket notification configuration\",\n",
    "            \"bucket\":{  \n",
    "               \"name\":\"s3://stock-market-raw-data-us-east-1/\",\n",
    "               \"ownerIdentity\":{  \n",
    "                  \"principalId\":\"Amazon-customer-ID-of-the-bucket-owner\"\n",
    "               },\n",
    "               \"arn\":\"arn:aws:s3:::stock-market-raw-data-us-east-1\"\n",
    "            },\n",
    "            \"object\":{  \n",
    "               \"key\":\"stg_price_by_date/20250131192045.csv\",\n",
    "               \"size\":\"object-size in bytes\",\n",
    "               \"eTag\":\"object eTag\",\n",
    "               \"versionId\":\"object version if bucket is versioning-enabled, otherwise null\",\n",
    "               \"sequencer\": \"a string representation of a hexadecimal value used to determine event sequence, only used with PUTs and DELETEs\"\n",
    "            }\n",
    "         },\n",
    "         \"glacierEventData\": {\n",
    "            \"restoreEventData\": {\n",
    "               \"lifecycleRestorationExpiryTime\": \"The time, in ISO-8601 format, for example, 1970-01-01T00:00:00.000Z, of Restore Expiry\",\n",
    "               \"lifecycleRestoreStorageClass\": \"Source storage class for restore\"\n",
    "            }\n",
    "         }\n",
    "      }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ''\n",
    "process_batch_files_lambda(event, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
